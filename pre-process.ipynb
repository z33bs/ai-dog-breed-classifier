{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make copy of images folder with smaller resized images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create mirror folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use rsync... modify input and output directory names before running\n",
    "#include directories with \\*/ \n",
    "#exclude files with \\*\n",
    "!rsync -a data sml80  --include \\*/ --exclude \\*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define custom dataset loader to save output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pay attention to required inputs: output directory, image dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ USER INPUTS ############\n",
    "out_dir = 'sml80'\n",
    "dims = (80, 80)\n",
    "###\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "\n",
    "def pil_loader_saver(path: str) -> Image.Image:\n",
    "    # To prevent: OSError: image file is truncated (150 bytes not processed)\n",
    "    # which throws when image truncated\n",
    "    ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "\n",
    "        # im_resized = img.resize((64, 64), reducing_gap = 2.0)\n",
    "        # see PIL documentation for details on optional optimisation: reducing_gap\n",
    "        # my understanding for speed so could be worse so no optim here\n",
    "        im_resized = img.resize(dims)\n",
    "\n",
    "#         im_resized.save('sml/{}'.format(path))\n",
    "        im_resized.save('{}/{}'.format(out_dir, path))\n",
    "        \n",
    "        return im_resized.convert('RGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo Loop through subfolders automatically and process for each\n",
    "\n",
    "############ USER INPUTS ############\n",
    "data_dir = 'data/dogImages' #laptop\n",
    "# data_dir = '/data/dog_images' #workspace\n",
    "###\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms \n",
    "\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', loader=pil_loader_saver, transform=transforms.ToTensor())\n",
    "valid_data = datasets.ImageFolder(data_dir + '/valid', loader=pil_loader_saver, transform=transforms.ToTensor())\n",
    "test_data = datasets.ImageFolder(data_dir + '/test', loader=pil_loader_saver, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=100)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=100)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100)\n",
    "\n",
    "print(\"Sample sizes:\\nTrain: {}\\tValid: {}\\tTest: {}\".format(len(train_data),len(valid_data),len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process by iterating through Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed=0\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    processed += len(data)\n",
    "    print(processed,end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed=0\n",
    "for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "    processed += len(data)\n",
    "    print(processed,end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed=0\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    processed += len(data)\n",
    "    print(processed,end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
